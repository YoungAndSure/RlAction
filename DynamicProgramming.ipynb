{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6164d561-df8a-4d40-a52e-53eea1da5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class CliffWalkingEnv:\n",
    "    \"\"\" 悬崖漫步环境\"\"\"\n",
    "    def __init__(self, ncol=12, nrow=4):\n",
    "        self.ncol = ncol  # 定义网格世界的列\n",
    "        self.nrow = nrow  # 定义网格世界的行\n",
    "        # 转移矩阵P[state][action] = [(p, next_state, reward, done)]包含下一个状态和奖励\n",
    "        self.P = self.createP()\n",
    "\n",
    "    def getState(self, i, j):\n",
    "        return i * self.ncol + j\n",
    "    \n",
    "    def createP(self):\n",
    "        # 初始化\n",
    "        P = [[[] for j in range(4)] for i in range(self.nrow * self.ncol)]\n",
    "        # 4种动作, change[0]:上,change[1]:下, change[2]:左, change[3]:右。坐标系原点(0,0)\n",
    "        # 定义在左上角\n",
    "        change = [[0, -1], [0, 1], [-1, 0], [1, 0]]\n",
    "        for i in range(self.nrow):\n",
    "            for j in range(self.ncol):\n",
    "                for a in range(4):\n",
    "                    # 位置在悬崖或者目标状态,因为无法继续交互,任何动作奖励都为0\n",
    "                    if i == self.nrow - 1 and j > 0:\n",
    "                        P[self.getState(i, j)][a] = [(1, self.getState(i, j), 0,\n",
    "                                                    True)]\n",
    "                        continue\n",
    "                    # 其他位置\n",
    "                    next_x = min(self.ncol - 1, max(0, j + change[a][0]))\n",
    "                    next_y = min(self.nrow - 1, max(0, i + change[a][1]))\n",
    "                    next_state = self.getState(next_y, next_x)\n",
    "                    reward = -1\n",
    "                    done = False\n",
    "                    # 下一个位置在悬崖或者终点\n",
    "                    if next_y == self.nrow - 1 and next_x > 0:\n",
    "                        done = True\n",
    "                        if next_x != self.ncol - 1:  # 下一个位置在悬崖\n",
    "                            reward = -100\n",
    "                    P[self.getState(i, j)][a] = [(1, next_state, reward, done)]\n",
    "        return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524110ea-6574-4016-9a21-622597d34661",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed9f1c-2bbf-4362-a26f-7a7bdedfd222",
   "metadata": {},
   "source": [
    "# Stop\n",
    "ok, 我已经看过《强化学习的数学原理》了，已经有了一个理论框架的主脉络，沿着这个主脉络拓展就好，不需要重新另起一套新的理解框架。况且这本书的框架搭的不太好，跳跃性太强。如果不是我已经读过数学原理，有些基础了，直接读这本书可以说寸步难行。  \n",
    "这本书的核心价值，是提供了示例代码，可以通过代码理解算法，和数学原理从公式理解互补。当然，鱼书也有示例代码，而且我也敲过，所以基础部分的代码意义也不大了，主要是高阶的TRPO、PPO等代码。  \n",
    "所以，我看这本书的核心目的，就是从代码上，理解一下高阶算法。从这个目的出发，完全不用从头到尾看一遍。直接看代码，对应背景介绍和论文，搞懂每一行代码含义即可。进度可以大大加快。  \n",
    "因此，笔记也到此为止了～准备从官方clone下来代码仓库，在官方代码仓库的基础上做笔记。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
